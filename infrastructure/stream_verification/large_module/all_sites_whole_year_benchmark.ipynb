{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, random, time\n",
    "import plotly\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumb setup stuff\\n\n",
    "import IPython.core.display as ipnb_display\n",
    "ipnb_display.display( ipnb_display.HTML(\"<style>.container { width:100% !important; }</style>\") )\n",
    "# matplotlib.rcParams['figure.figsize'] = [8, 5\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = '{:,f}'.format\n",
    "\n",
    "pio.templates[\"ians_template\"] = go.layout.Template(\n",
    "  layout = go.Layout(\n",
    "    height = 900\n",
    "  )\n",
    ")\n",
    "pio.templates.default = \"ians_template\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ParFlowStreamVerification_Large import *\n",
    "import climata.usgs as usgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations map\n",
    "stations_map_path = \"NWM_Gage_Adjustments_attribute_table_20200510.csv\"\n",
    "station_map = load_station_mapping_as_DataFrame( stations_map_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_data( station_ids, parameter_id=default_parameter_id, start_date=None, end_date=None, date_range=None ):\n",
    "  # Check proper usage of date parameters\n",
    "  if (start_date is None or end_date is None) and date_range is None:\n",
    "    raise ValueError(\"load_station_data_over_date_range_as_DataFrame must use either both start and end dates, or date_range\")\n",
    "\n",
    "  # Properly cast station and parameter ids\n",
    "  station_ids = [ station_id_cast( station_id ) for station_id in station_ids ]\n",
    "  parameter_id = parameter_id_cast( parameter_id )\n",
    " \n",
    "#   print( station_ids )\n",
    "  \n",
    "  # Create date-range\n",
    "  # From provided time-period parameters\n",
    "  if date_range is None:\n",
    "    date_range_list = pd.date_range( start=start_date, end=end_date ).tolist()\n",
    "  # From provided list of dates\n",
    "  elif isinstance( date_range, list ):\n",
    "    date_range_list = sorted( date_range )\n",
    "  # From provided pandas DatetimeIndex\n",
    "  elif isinstance( date_range, pandas.core.indexes.datetimes.DatetimeIndex ):\n",
    "    date_range_list = date_range.tolist()\n",
    "\n",
    "  using_start_date = date_range_list[0]\n",
    "  using_end_date = date_range_list[-1]\n",
    "  \n",
    "  # Generator to download data in batches\n",
    "  batch_size = 500\n",
    "  batched_station_requests = (\n",
    "    usgs.DailyValueIO(\n",
    "      start_date = using_start_date,\n",
    "      end_date   = using_end_date,\n",
    "      station    = station_ids[batch_station_ids_index:batch_station_ids_index+batch_size],\n",
    "      parameter  = parameter_id\n",
    "    )\n",
    "    for batch_station_ids_index in range(0,len(station_ids),batch_size)\n",
    "  )\n",
    "  \n",
    "#   for request in station_requests:\n",
    "#     print( request )\n",
    "#   print(\"=============\")\n",
    "#   for request in station_requests:\n",
    "#     print( request )\n",
    "#     for value_object in request.data:\n",
    "#       print( value_object )\n",
    "      \n",
    "  # climata.usgs.DailyValueIO claims to be iterable, but in practice there is nothing to iterate over...\n",
    "  # Note the IO obeject annot be exhausted\n",
    "  #(ie, it can be iterated over multiple times to get the different aspects of the request(s) from it)\n",
    "\n",
    "  # Flatten data into list of dictionaries with the data and flow extracted\n",
    "  # Note this is a generator, which *CAN* be exhausted. Only use *ONCE*!\n",
    "  flattened_data_generator = (\n",
    "    {\n",
    "      \"station\"                                : station_id_cast(request.site_code),\n",
    "      \"date\"                                   : date_value_object.date,\n",
    "      parameter_id_cast(request.variable_code) : date_value_object.value\n",
    "    }\n",
    "    for station_requests in batched_station_requests\n",
    "    for request in station_requests\n",
    "    for date_value_object in request.data\n",
    "  )\n",
    "\n",
    "  # Create DatFrame from the flattened generator.\n",
    "  station_data = pd.DataFrame(\n",
    "    columns = [\"station\", \"date\", parameter_id],\n",
    "    data    = flattened_data_generator,\n",
    "  ).sort_values( [\"station\", \"date\"] )\n",
    "\n",
    "#   if station_data.index.size == 0:\n",
    "#     raise RuntimeError(f\"Stations {station_ids} does not have data for parameters {parameter_id} for date range {using_start_date} - {using_end_date}\")\n",
    "\n",
    "  return station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data-range\n",
    "end_date = \"2010-12-31\"\n",
    "periods = 365\n",
    "date_range = pd.date_range(end=end_date, periods=periods).tolist()\n",
    "start_date = date_range[0]\n",
    "\n",
    "stations = station_map.STNID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f\"expect {len(date_range) * len(stations)} rows\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pid in range(0,101):\n",
    "#   get_multiple_data( station_ids=[station_map.STNID[0]], parameter_ids=[pid], date_range=date_range)\n",
    "\n",
    "start = time.perf_counter()\n",
    "all_station_data = get_multiple_data( station_ids=stations, date_range=date_range)\n",
    "end = time.perf_counter()\n",
    "\n",
    "elapsed = end - start\n",
    "print( f\"elapsed {elapsed}s\" )\n",
    "print( f\"elapsed {elapsed/len(all_station_data)} s/station-day\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( all_station_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
